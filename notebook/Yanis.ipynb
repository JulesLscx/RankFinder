{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Existe t-il une corrélation entre l’éditeur et le commentaire (score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "PATH_RATING = '../data/Books_rating_t.csv'\n",
    "PATH_BOOKS = '../data/books_data_t.csv'\n",
    "PATH_SAMPLE_RATING = '../data/Sample_Books_rating.csv'\n",
    "\n",
    "rating = pd.read_csv(PATH_SAMPLE_RATING)\n",
    "books = pd.read_csv(PATH_BOOKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titre</th>\n",
       "      <th>Description</th>\n",
       "      <th>Auteurs</th>\n",
       "      <th>Image</th>\n",
       "      <th>Lien Google</th>\n",
       "      <th>Editeur</th>\n",
       "      <th>Date publication</th>\n",
       "      <th>infoLink</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Nb scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Its Only Art If Its Well Hung!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Julie Strain']</td>\n",
       "      <td>http://books.google.com/books/content?id=DykPA...</td>\n",
       "      <td>http://books.google.nl/books?id=DykPAAAACAAJ&amp;d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1996</td>\n",
       "      <td>http://books.google.nl/books?id=DykPAAAACAAJ&amp;d...</td>\n",
       "      <td>['Comics &amp; Graphic Novels']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>Philip Nel takes a fascinating look into the k...</td>\n",
       "      <td>['Philip Nel']</td>\n",
       "      <td>http://books.google.com/books/content?id=IjvHQ...</td>\n",
       "      <td>http://books.google.nl/books?id=IjvHQsCn_pgC&amp;p...</td>\n",
       "      <td>A&amp;C Black</td>\n",
       "      <td>01/01/2005</td>\n",
       "      <td>http://books.google.nl/books?id=IjvHQsCn_pgC&amp;d...</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wonderful Worship in Smaller Churches</td>\n",
       "      <td>This resource includes twelve principles in un...</td>\n",
       "      <td>['David R. Ray']</td>\n",
       "      <td>http://books.google.com/books/content?id=2tsDA...</td>\n",
       "      <td>http://books.google.nl/books?id=2tsDAAAACAAJ&amp;d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>http://books.google.nl/books?id=2tsDAAAACAAJ&amp;d...</td>\n",
       "      <td>['Religion']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Whispers of the Wicked Saints</td>\n",
       "      <td>Julia Thomas finds her life spinning out of co...</td>\n",
       "      <td>['Veronica Haddon']</td>\n",
       "      <td>http://books.google.com/books/content?id=aRSIg...</td>\n",
       "      <td>http://books.google.nl/books?id=aRSIgJlq6JwC&amp;d...</td>\n",
       "      <td>iUniverse</td>\n",
       "      <td>2005-02</td>\n",
       "      <td>http://books.google.nl/books?id=aRSIgJlq6JwC&amp;d...</td>\n",
       "      <td>['Fiction']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nation Dance: Religion, Identity and Cultural ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Edward Long']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://books.google.nl/books?id=399SPgAACAAJ&amp;d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/03/2003</td>\n",
       "      <td>http://books.google.nl/books?id=399SPgAACAAJ&amp;d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Church of Christ: A Biblical Ecclesiology ...</td>\n",
       "      <td>In The Church of Christ: A Biblical Ecclesiolo...</td>\n",
       "      <td>['Everett Ferguson']</td>\n",
       "      <td>http://books.google.com/books/content?id=kVqRa...</td>\n",
       "      <td>http://books.google.nl/books?id=kVqRaiPlx88C&amp;p...</td>\n",
       "      <td>Wm. B. Eerdmans Publishing</td>\n",
       "      <td>1996</td>\n",
       "      <td>http://books.google.nl/books?id=kVqRaiPlx88C&amp;d...</td>\n",
       "      <td>['Religion']</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Overbury affair (Avon)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Miriam Allen De Ford']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://books.google.nl/books?id=mHLTngEACAAJ&amp;d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1960</td>\n",
       "      <td>http://books.google.nl/books?id=mHLTngEACAAJ&amp;d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A Walk in the Woods: a Play in Two Acts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Lee Blessing']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://books.google.nl/books?id=6HDOwAEACAAJ&amp;d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1988</td>\n",
       "      <td>http://books.google.nl/books?id=6HDOwAEACAAJ&amp;d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Saint Hyacinth of Poland</td>\n",
       "      <td>The story for children 10 and up of St. Hyacin...</td>\n",
       "      <td>['Mary Fabyan Windeatt']</td>\n",
       "      <td>http://books.google.com/books/content?id=lmLqA...</td>\n",
       "      <td>http://books.google.nl/books?id=lmLqAAAACAAJ&amp;d...</td>\n",
       "      <td>Tan Books &amp; Pub</td>\n",
       "      <td>01/01/2009</td>\n",
       "      <td>http://books.google.nl/books?id=lmLqAAAACAAJ&amp;d...</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rising Sons and Daughters: Life Among Japan's ...</td>\n",
       "      <td>Wardell recalls his experience as a foreign st...</td>\n",
       "      <td>['Steven Wardell']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://books.google.nl/books?id=rbLZugEACAAJ&amp;d...</td>\n",
       "      <td>Plympton PressIntl</td>\n",
       "      <td>1995</td>\n",
       "      <td>http://books.google.nl/books?id=rbLZugEACAAJ&amp;d...</td>\n",
       "      <td>['Social Science']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Titre  \\\n",
       "0                     Its Only Art If Its Well Hung!   \n",
       "1                           Dr. Seuss: American Icon   \n",
       "2              Wonderful Worship in Smaller Churches   \n",
       "3                      Whispers of the Wicked Saints   \n",
       "4  Nation Dance: Religion, Identity and Cultural ...   \n",
       "5  The Church of Christ: A Biblical Ecclesiology ...   \n",
       "6                         The Overbury affair (Avon)   \n",
       "7            A Walk in the Woods: a Play in Two Acts   \n",
       "8                           Saint Hyacinth of Poland   \n",
       "9  Rising Sons and Daughters: Life Among Japan's ...   \n",
       "\n",
       "                                         Description  \\\n",
       "0                                                NaN   \n",
       "1  Philip Nel takes a fascinating look into the k...   \n",
       "2  This resource includes twelve principles in un...   \n",
       "3  Julia Thomas finds her life spinning out of co...   \n",
       "4                                                NaN   \n",
       "5  In The Church of Christ: A Biblical Ecclesiolo...   \n",
       "6                                                NaN   \n",
       "7                                                NaN   \n",
       "8  The story for children 10 and up of St. Hyacin...   \n",
       "9  Wardell recalls his experience as a foreign st...   \n",
       "\n",
       "                    Auteurs  \\\n",
       "0          ['Julie Strain']   \n",
       "1            ['Philip Nel']   \n",
       "2          ['David R. Ray']   \n",
       "3       ['Veronica Haddon']   \n",
       "4           ['Edward Long']   \n",
       "5      ['Everett Ferguson']   \n",
       "6  ['Miriam Allen De Ford']   \n",
       "7          ['Lee Blessing']   \n",
       "8  ['Mary Fabyan Windeatt']   \n",
       "9        ['Steven Wardell']   \n",
       "\n",
       "                                               Image  \\\n",
       "0  http://books.google.com/books/content?id=DykPA...   \n",
       "1  http://books.google.com/books/content?id=IjvHQ...   \n",
       "2  http://books.google.com/books/content?id=2tsDA...   \n",
       "3  http://books.google.com/books/content?id=aRSIg...   \n",
       "4                                                NaN   \n",
       "5  http://books.google.com/books/content?id=kVqRa...   \n",
       "6                                                NaN   \n",
       "7                                                NaN   \n",
       "8  http://books.google.com/books/content?id=lmLqA...   \n",
       "9                                                NaN   \n",
       "\n",
       "                                         Lien Google  \\\n",
       "0  http://books.google.nl/books?id=DykPAAAACAAJ&d...   \n",
       "1  http://books.google.nl/books?id=IjvHQsCn_pgC&p...   \n",
       "2  http://books.google.nl/books?id=2tsDAAAACAAJ&d...   \n",
       "3  http://books.google.nl/books?id=aRSIgJlq6JwC&d...   \n",
       "4  http://books.google.nl/books?id=399SPgAACAAJ&d...   \n",
       "5  http://books.google.nl/books?id=kVqRaiPlx88C&p...   \n",
       "6  http://books.google.nl/books?id=mHLTngEACAAJ&d...   \n",
       "7  http://books.google.nl/books?id=6HDOwAEACAAJ&d...   \n",
       "8  http://books.google.nl/books?id=lmLqAAAACAAJ&d...   \n",
       "9  http://books.google.nl/books?id=rbLZugEACAAJ&d...   \n",
       "\n",
       "                      Editeur Date publication  \\\n",
       "0                         NaN             1996   \n",
       "1                   A&C Black       01/01/2005   \n",
       "2                         NaN             2000   \n",
       "3                   iUniverse          2005-02   \n",
       "4                         NaN       01/03/2003   \n",
       "5  Wm. B. Eerdmans Publishing             1996   \n",
       "6                         NaN             1960   \n",
       "7                         NaN             1988   \n",
       "8             Tan Books & Pub       01/01/2009   \n",
       "9          Plympton PressIntl             1995   \n",
       "\n",
       "                                            infoLink  \\\n",
       "0  http://books.google.nl/books?id=DykPAAAACAAJ&d...   \n",
       "1  http://books.google.nl/books?id=IjvHQsCn_pgC&d...   \n",
       "2  http://books.google.nl/books?id=2tsDAAAACAAJ&d...   \n",
       "3  http://books.google.nl/books?id=aRSIgJlq6JwC&d...   \n",
       "4  http://books.google.nl/books?id=399SPgAACAAJ&d...   \n",
       "5  http://books.google.nl/books?id=kVqRaiPlx88C&d...   \n",
       "6  http://books.google.nl/books?id=mHLTngEACAAJ&d...   \n",
       "7  http://books.google.nl/books?id=6HDOwAEACAAJ&d...   \n",
       "8  http://books.google.nl/books?id=lmLqAAAACAAJ&d...   \n",
       "9  http://books.google.nl/books?id=rbLZugEACAAJ&d...   \n",
       "\n",
       "                           Genre  Nb scores  \n",
       "0    ['Comics & Graphic Novels']        NaN  \n",
       "1  ['Biography & Autobiography']        NaN  \n",
       "2                   ['Religion']        NaN  \n",
       "3                    ['Fiction']        NaN  \n",
       "4                            NaN        NaN  \n",
       "5                   ['Religion']        5.0  \n",
       "6                            NaN        NaN  \n",
       "7                            NaN        3.0  \n",
       "8  ['Biography & Autobiography']        NaN  \n",
       "9             ['Social Science']        NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Titre</th>\n",
       "      <th>Prix</th>\n",
       "      <th>User_id</th>\n",
       "      <th>Nom lecteur</th>\n",
       "      <th>revue/utilité</th>\n",
       "      <th>revue/score</th>\n",
       "      <th>revue/heure</th>\n",
       "      <th>revue/résumé</th>\n",
       "      <th>revue/texte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0006CR6U4</td>\n",
       "      <td>A dictionary of the Targumim, the Talmud Babli...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A303XPDO694V6X</td>\n",
       "      <td>Ariel</td>\n",
       "      <td>2/6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1122163200</td>\n",
       "      <td>Jastrow</td>\n",
       "      <td>Jastrow made a great workthis dictionary can h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0897166159</td>\n",
       "      <td>Espresso Coffee: Professional Techniques</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A3780H4TM9RMB8</td>\n",
       "      <td>David barnes</td>\n",
       "      <td>0/1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1356912000</td>\n",
       "      <td>NOT the book</td>\n",
       "      <td>Extremely disappointed by the SHORT length and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0736693408</td>\n",
       "      <td>The First King of Shannara (The Sword of Shann...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A1AX6VPDQQZDPV</td>\n",
       "      <td>M Carlton</td>\n",
       "      <td>4/4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1105574400</td>\n",
       "      <td>Great (what do you expect?)</td>\n",
       "      <td>This, like all of Brook's Shannara series book...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0395051029</td>\n",
       "      <td>Wuthering Heights (Riverside editions)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A35RQKCCCQ62O0</td>\n",
       "      <td>LadyJ</td>\n",
       "      <td>0/0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1353888000</td>\n",
       "      <td>Satisfied</td>\n",
       "      <td>I enjoyed this classic. I didn't know the stor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4770016050</td>\n",
       "      <td>A Cat, a Man, and Two Women (Japans Modern Wri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A2IJQDE1I4SIJT</td>\n",
       "      <td>David C. Arnold \"master D\"</td>\n",
       "      <td>1/2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1167955200</td>\n",
       "      <td>Ordered 09/02/2006, still on backorder</td>\n",
       "      <td>I would love to read this book. Have accepted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B000GP9E9C</td>\n",
       "      <td>More Than Human</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A3P92F9JAZQPIE</td>\n",
       "      <td>F Funney \"CatMan\"</td>\n",
       "      <td>1/2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1265846400</td>\n",
       "      <td>gestalt!</td>\n",
       "      <td>bless you! lol... sorry, but you just have to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B000N2HCQU</td>\n",
       "      <td>The Checklist: How to Identify True Medical Ad...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A178LDK1GMX9M6</td>\n",
       "      <td>A. Cacioli</td>\n",
       "      <td>5/6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1169683200</td>\n",
       "      <td>Well Done!!!!</td>\n",
       "      <td>Thank you, Dr. Manny. This book was such an in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B0007EW3SG</td>\n",
       "      <td>Black lamb and grey falcon: A journey through ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>992995200</td>\n",
       "      <td>Great Insight into Balkans</td>\n",
       "      <td>For anyone living in or traveling to the Balka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0590449729</td>\n",
       "      <td>Two Crazy Pigs (Hello Reader, Level 2)</td>\n",
       "      <td>3.4</td>\n",
       "      <td>ACUX3DS8PZ1HV</td>\n",
       "      <td>Diane</td>\n",
       "      <td>3/4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1163203200</td>\n",
       "      <td>great book for kids, super photos!</td>\n",
       "      <td>I am a teacher and use this book with my Engli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B000KAHM5Q</td>\n",
       "      <td>Love You Forever</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0/1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>948672000</td>\n",
       "      <td>Very sweet childrens book....a true mothers lo...</td>\n",
       "      <td>My teacher read this to our 8th grade lit. cla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id                                              Titre  Prix  \\\n",
       "0  B0006CR6U4  A dictionary of the Targumim, the Talmud Babli...   NaN   \n",
       "1  0897166159           Espresso Coffee: Professional Techniques   NaN   \n",
       "2  0736693408  The First King of Shannara (The Sword of Shann...   NaN   \n",
       "3  0395051029             Wuthering Heights (Riverside editions)   NaN   \n",
       "4  4770016050  A Cat, a Man, and Two Women (Japans Modern Wri...   NaN   \n",
       "5  B000GP9E9C                                    More Than Human   NaN   \n",
       "6  B000N2HCQU  The Checklist: How to Identify True Medical Ad...   NaN   \n",
       "7  B0007EW3SG  Black lamb and grey falcon: A journey through ...   NaN   \n",
       "8  0590449729             Two Crazy Pigs (Hello Reader, Level 2)   3.4   \n",
       "9  B000KAHM5Q                                   Love You Forever   NaN   \n",
       "\n",
       "          User_id                 Nom lecteur revue/utilité  revue/score  \\\n",
       "0  A303XPDO694V6X                       Ariel           2/6          4.0   \n",
       "1  A3780H4TM9RMB8                David barnes           0/1          2.0   \n",
       "2  A1AX6VPDQQZDPV                   M Carlton           4/4          5.0   \n",
       "3  A35RQKCCCQ62O0                       LadyJ           0/0          4.0   \n",
       "4  A2IJQDE1I4SIJT  David C. Arnold \"master D\"           1/2          5.0   \n",
       "5  A3P92F9JAZQPIE           F Funney \"CatMan\"           1/2          5.0   \n",
       "6  A178LDK1GMX9M6                  A. Cacioli           5/6          5.0   \n",
       "7             NaN                         NaN           8/9          5.0   \n",
       "8   ACUX3DS8PZ1HV                       Diane           3/4          5.0   \n",
       "9             NaN                         NaN           0/1          5.0   \n",
       "\n",
       "   revue/heure                                       revue/résumé  \\\n",
       "0   1122163200                                            Jastrow   \n",
       "1   1356912000                                       NOT the book   \n",
       "2   1105574400                        Great (what do you expect?)   \n",
       "3   1353888000                                          Satisfied   \n",
       "4   1167955200             Ordered 09/02/2006, still on backorder   \n",
       "5   1265846400                                           gestalt!   \n",
       "6   1169683200                                      Well Done!!!!   \n",
       "7    992995200                         Great Insight into Balkans   \n",
       "8   1163203200                 great book for kids, super photos!   \n",
       "9    948672000  Very sweet childrens book....a true mothers lo...   \n",
       "\n",
       "                                         revue/texte  \n",
       "0  Jastrow made a great workthis dictionary can h...  \n",
       "1  Extremely disappointed by the SHORT length and...  \n",
       "2  This, like all of Brook's Shannara series book...  \n",
       "3  I enjoyed this classic. I didn't know the stor...  \n",
       "4  I would love to read this book. Have accepted ...  \n",
       "5  bless you! lol... sorry, but you just have to ...  \n",
       "6  Thank you, Dr. Manny. This book was such an in...  \n",
       "7  For anyone living in or traveling to the Balka...  \n",
       "8  I am a teacher and use this book with my Engli...  \n",
       "9  My teacher read this to our 8th grade lit. cla...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Titre  \\\n",
      "0  FORCE, RECIPROCAL FORCE AND COMPRESSION CAUSE ...   \n",
      "1  Raising Gifted Kids: Everything You Need to Kn...   \n",
      "2  Lifetimes: The Beautiful Way to Explain Death ...   \n",
      "3                                    The Dharma Bums   \n",
      "4           The Ultimate Guide to Freshwater Fishing   \n",
      "\n",
      "                     Editeur  revue/score  \n",
      "0                        NaN          1.0  \n",
      "1               Amacom Books          1.0  \n",
      "2                     Bantam          5.0  \n",
      "3                 Penguin UK          5.0  \n",
      "4  Publishing Solutions, LLC          5.0  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>revue/score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>revue/score</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             revue/score\n",
       "revue/score          1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "rating = rating.dropna()\n",
    "\n",
    "# Merge the \"rating\" and \"books\" dataframes\n",
    "merged_data = pd.merge(books[['Titre','Editeur']], rating[['Titre','revue/score']], on='Titre')\n",
    "print(merged_data.head())\n",
    "\n",
    "# Calculate the correlation between the \"publisher\" and \"score\" columns\n",
    "correlation_editeur_score = merged_data.corr(numeric_only=True)\n",
    "\n",
    "# Print the correlation\n",
    "correlation_editeur_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>revue/score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>revue/score</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             revue/score\n",
       "revue/score          1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the correlation between the \"publisher\" and \"score\" columns\n",
    "correlation_editeur_score = merged_data.corr(numeric_only=True)\n",
    "# Print the correlation\n",
    "correlation_editeur_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00' '000' '001' ... 'zulus' 'zweibel' 'zwerg']\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "The accuracy of the KNN model is : 0.6470588235294118\n"
     ]
    }
   ],
   "source": [
    "# Generate countvectorizer for revenue/texte\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(rating['revue/texte'])\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(X.toarray())\n",
    "Y = rating['revue/score']\n",
    "\n",
    "# Normalize the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X.toarray())\n",
    "\n",
    "# Split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a KNN model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=100)\n",
    "knn.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions\n",
    "Y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_KNN = accuracy_score(Y_test, Y_pred)\n",
    "print(\"The accuracy of the KNN model is :\", accuracy_KNN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00' '000' '001' ... 'zulus' 'zweibel' 'zwerg']\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "The accuracy of the Logistic Regression model is : 0.6691176470588235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yanis Afrite\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate countvectorizer for revenue/texte\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(rating['revue/texte'])\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(X.toarray())\n",
    "Y = rating['revue/score']\n",
    "\n",
    "# Normalize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X.toarray())\n",
    "\n",
    "# Split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions\n",
    "Y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_log_reg = accuracy_score(Y_test, Y_pred)\n",
    "print(\"The accuracy of the Logistic Regression model is :\", accuracy_log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00' '000' '001' ... 'zulus' 'zweibel' 'zwerg']\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "The accuracy of the Decision Tree model is : 0.47058823529411764\n"
     ]
    }
   ],
   "source": [
    "# Generate countvectorizer for revenue/texte\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(rating['revue/texte'])\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(X.toarray())\n",
    "Y = rating['revue/score']\n",
    "\n",
    "# Normalize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X.toarray())\n",
    "\n",
    "# Split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Decision Tree model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions\n",
    "Y_pred = tree.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_tree = accuracy_score(Y_test, Y_pred)\n",
    "print(\"The accuracy of the Decision Tree model is :\", accuracy_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00' '000' '001' ... 'zulus' 'zweibel' 'zwerg']\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "The accuracy of the Random Forest model is : 0.6433823529411765\n"
     ]
    }
   ],
   "source": [
    "# Generate countvectorizer for revenue/texte\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(rating['revue/texte'])\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(X.toarray())\n",
    "Y = rating['revue/score']\n",
    "\n",
    "# Normalize the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X.toarray())\n",
    "\n",
    "# Split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier()\n",
    "forest.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions\n",
    "Y_pred = forest.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_forest = accuracy_score(Y_test, Y_pred)\n",
    "print(\"The accuracy of the Random Forest model is :\", accuracy_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00' '000' '001' ... 'zulus' 'zweibel' 'zwerg']\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "The accuracy of the Gradient Boosting model is : 0.6286764705882353\n"
     ]
    }
   ],
   "source": [
    "# Generate countvectorizer for revue/texte\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(rating['revue/texte'])\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(X.toarray())\n",
    "Y = rating['revue/score']\n",
    "\n",
    "# Normalize the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X.toarray())\n",
    "\n",
    "# Split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Gradient Boosting model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions\n",
    "Y_pred = gb.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_gb = accuracy_score(Y_test, Y_pred)\n",
    "print(\"The accuracy of the Gradient Boosting model is :\", accuracy_gb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00' '000' '001' ... 'zulus' 'zweibel' 'zwerg']\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "The accuracy of the adaBoost model is : 0.6029411764705882\n"
     ]
    }
   ],
   "source": [
    "# Generate countvectorizer for revue/texte\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(rating['revue/texte'])\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(X.toarray())\n",
    "Y = rating['revue/score']\n",
    "\n",
    "# Normalize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X.toarray())\n",
    "\n",
    "# Split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a adaBoost model\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions\n",
    "Y_pred = ada.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_ada = accuracy_score(Y_test, Y_pred)\n",
    "print(\"The accuracy of the adaBoost model is :\", accuracy_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00' '000' '001' ... 'zulus' 'zweibel' 'zwerg']\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "The accuracy of the SVM model is : 0.6507352941176471\n"
     ]
    }
   ],
   "source": [
    "# Generate countvectorizer for revue/texte\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(rating['revue/texte'])\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(X.toarray())\n",
    "Y = rating['revue/score']\n",
    "\n",
    "# Normalize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X.toarray())\n",
    "\n",
    "# Split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a SVM model with a linear kernel\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions\n",
    "Y_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_svm = accuracy_score(Y_test, Y_pred)\n",
    "print(\"The accuracy of the SVM model is :\", accuracy_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00' '000' '001' ... 'zulus' 'zweibel' 'zwerg']\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "The accuracy of the SVM model with a rbf kernel is : 0.6507352941176471\n"
     ]
    }
   ],
   "source": [
    "# Generate countvectorizer for revue/texte\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(rating['revue/texte'])\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(X.toarray())\n",
    "Y = rating['revue/score']\n",
    "\n",
    "# Normalize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X.toarray())\n",
    "\n",
    "# Split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a SVM model with a kernel\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions\n",
    "Y_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_svm_rbf = accuracy_score(Y_test, Y_pred)\n",
    "print(\"The accuracy of the SVM model with a rbf kernel is :\", accuracy_svm_rbf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00' '000' '001' ... 'zulus' 'zweibel' 'zwerg']\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "The accuracy of the MLP Classifier model is : 0.31985294117647056\n"
     ]
    }
   ],
   "source": [
    "# Generate countvectorizer for revue/texte\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(rating['revue/texte'])\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(X.toarray())\n",
    "Y = rating['revue/score']\n",
    "\n",
    "# Normalize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X.toarray())\n",
    "\n",
    "# Split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a MLP Classifier model  \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier()\n",
    "mlp.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions\n",
    "Y_pred = mlp.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_mlp = accuracy_score(Y_test, Y_pred)\n",
    "print(\"The accuracy of the MLP Classifier model is :\", accuracy_mlp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
