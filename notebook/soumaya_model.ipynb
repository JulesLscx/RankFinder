{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.1124572141135383\n",
      "R² score: 0.2367695592690694\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "file_path = '../data/Sample_Books_rating.csv'  \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "data_clean = data.dropna(subset=['revue/texte', 'revue/score'])\n",
    "\n",
    "# Séparation des données en ensembles d'entraînement et de test\n",
    "X = data_clean['revue/texte']\n",
    "y = data_clean['revue/score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorisation des textes avec TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "# Entraînement du modèle \n",
    "model = LinearRegression()\n",
    "model.fit(X_train_vect, y_train)\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "y_pred = model.predict(X_test_vect)\n",
    "\n",
    "# Évaluation du modèle\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'R² score: {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Id                                              Titre  Prix  \\\n",
      "0  B0006CR6U4  A dictionary of the Targumim, the Talmud Babli...   NaN   \n",
      "1  0897166159           Espresso Coffee: Professional Techniques   NaN   \n",
      "2  0736693408  The First King of Shannara (The Sword of Shann...   NaN   \n",
      "3  0395051029             Wuthering Heights (Riverside editions)   NaN   \n",
      "4  4770016050  A Cat, a Man, and Two Women (Japans Modern Wri...   NaN   \n",
      "\n",
      "          User_id                 Nom lecteur revue/utilité  revue/score  \\\n",
      "0  A303XPDO694V6X                       Ariel           2/6          4.0   \n",
      "1  A3780H4TM9RMB8                David barnes           0/1          2.0   \n",
      "2  A1AX6VPDQQZDPV                   M Carlton           4/4          5.0   \n",
      "3  A35RQKCCCQ62O0                       LadyJ           0/0          4.0   \n",
      "4  A2IJQDE1I4SIJT  David C. Arnold \"master D\"           1/2          5.0   \n",
      "\n",
      "   revue/heure                            revue/résumé  \\\n",
      "0   1122163200                                 Jastrow   \n",
      "1   1356912000                            NOT the book   \n",
      "2   1105574400             Great (what do you expect?)   \n",
      "3   1353888000                               Satisfied   \n",
      "4   1167955200  Ordered 09/02/2006, still on backorder   \n",
      "\n",
      "                                         revue/texte  \n",
      "0  Jastrow made a great workthis dictionary can h...  \n",
      "1  Extremely disappointed by the SHORT length and...  \n",
      "2  This, like all of Brook's Shannara series book...  \n",
      "3  I enjoyed this classic. I didn't know the stor...  \n",
      "4  I would love to read this book. Have accepted ...  \n",
      "accuracy :  0.6045\n",
      "RMSE: 1.342013412749664\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "data = pd.read_csv('../data/Sample_Books_rating.csv')\n",
    "print(data.head())\n",
    "data.dropna(subset=['revue/texte', 'revue/score'], inplace=True)\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(data['revue/texte'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, data['revue/score'], test_size=0.2, random_state=42)\n",
    "\n",
    "model =AdaBoostClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "print('accuracy : ', model.score(X_test, y_test))\n",
    "print('RMSE:', mean_squared_error(y_test, predictions, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Id                                              Titre  Prix  \\\n",
      "0  B0006CR6U4  A dictionary of the Targumim, the Talmud Babli...   NaN   \n",
      "1  0897166159           Espresso Coffee: Professional Techniques   NaN   \n",
      "2  0736693408  The First King of Shannara (The Sword of Shann...   NaN   \n",
      "3  0395051029             Wuthering Heights (Riverside editions)   NaN   \n",
      "4  4770016050  A Cat, a Man, and Two Women (Japans Modern Wri...   NaN   \n",
      "\n",
      "          User_id                 Nom lecteur revue/utilité  revue/score  \\\n",
      "0  A303XPDO694V6X                       Ariel           2/6          4.0   \n",
      "1  A3780H4TM9RMB8                David barnes           0/1          2.0   \n",
      "2  A1AX6VPDQQZDPV                   M Carlton           4/4          5.0   \n",
      "3  A35RQKCCCQ62O0                       LadyJ           0/0          4.0   \n",
      "4  A2IJQDE1I4SIJT  David C. Arnold \"master D\"           1/2          5.0   \n",
      "\n",
      "   revue/heure                            revue/résumé  \\\n",
      "0   1122163200                                 Jastrow   \n",
      "1   1356912000                            NOT the book   \n",
      "2   1105574400             Great (what do you expect?)   \n",
      "3   1353888000                               Satisfied   \n",
      "4   1167955200  Ordered 09/02/2006, still on backorder   \n",
      "\n",
      "                                         revue/texte  \n",
      "0  Jastrow made a great workthis dictionary can h...  \n",
      "1  Extremely disappointed by the SHORT length and...  \n",
      "2  This, like all of Brook's Shannara series book...  \n",
      "3  I enjoyed this classic. I didn't know the stor...  \n",
      "4  I would love to read this book. Have accepted ...  \n",
      "accuracy :  0.605\n",
      "RMSE: 1.4065916251705752\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer,  TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('../data/Sample_Books_rating.csv')\n",
    "print(data.head())\n",
    "\n",
    "# Preprocess the data\n",
    "data.dropna(subset=['revue/texte', 'revue/score'], inplace=True)\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "X = vectorizer.fit_transform(data['revue/texte'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, data['revue/score'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Decision Tree model\n",
    "#model = DecisionTreeClassifier()\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = model.predict(X_test)\n",
    "print('accuracy : ', model.score(X_test, y_test))\n",
    "print('RMSE:', mean_squared_error(y_test, predictions, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tokenizer\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequence\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pad_sequences\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\__init__.py:39\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python'"
     ]
    }
   ],
   "source": [
    "## LLM fait avec keras pour le score de livre\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense, Dropout  # Ajout de Dropout ici\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint  # Assurez-vous d'importer ModelCheckpoint si vous l'utilisez\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# Charger les données\n",
    "data_path = 'Sample_Books_rating.csv'  \n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Nettoyage des données pour éliminer les lignes sans texte de commentaire\n",
    "data_clean = data.dropna(subset=['revue/texte', 'revue/score'])\n",
    "\n",
    "X = data_clean['revue/texte'].values\n",
    "y = data_clean['revue/score'].values\n",
    "\n",
    "# Normalisation des scores pour la régression\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "y = scaler.fit_transform(y.reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "# Préparation des données textuelles\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X)\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "X_padded = pad_sequences(sequences, maxlen=100)\n",
    "\n",
    "# Division des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modification de la construction du modèle pour inclure Dropout et une fonction d'activation linéaire\n",
    "model = Sequential([\n",
    "    Embedding(10000, 16, input_length=100),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.5),  # Ajout de Dropout pour la régularisation\n",
    "    Dense(1, activation='linear')  # Changement pour une fonction d'activation linéaire\n",
    "])\n",
    "\n",
    "# Modification de l'optimiseur pour un taux d'apprentissage différent si nécessaire\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks pour l'arrêt anticipé et la sauvegarde du meilleur modèle\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Entraînement du modèle avec les callbacks\n",
    "model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), batch_size=32,\n",
    "          callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "# Charger le meilleur modèle sauvegardé\n",
    "model.load_weights('best_model.h5')\n",
    "\n",
    "# Prédiction sur l'ensemble de test avec le meilleur modèle\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_rescaled = scaler.inverse_transform(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LLM fait avec pytorch pour le score de livre\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Charger les données\n",
    "data_path = 'Sample_Books_rating.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Nettoyage des données\n",
    "data_clean = data.dropna(subset=['revue/texte', 'revue/score'])\n",
    "\n",
    "# Normalisation des scores\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "y = scaler.fit_transform(data_clean['revue/score'].values.reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "# Préparation des données textuelles avec PyTorch\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(data_clean['revue/texte'].values)\n",
    "sequences = tokenizer.texts_to_sequences(data_clean['revue/texte'].values)\n",
    "X_padded = pad_sequences(sequences, maxlen=100)\n",
    "\n",
    "# Division des données\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Définir un Dataset personnalisé\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, reviews, scores):\n",
    "        self.reviews = torch.tensor(reviews, dtype=torch.long)\n",
    "        self.scores = torch.tensor(scores, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.reviews[idx], self.scores[idx]\n",
    "\n",
    "train_dataset = ReviewDataset(X_train, y_train)\n",
    "test_dataset = ReviewDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# Définir le modèle\n",
    "class ReviewRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReviewRegressor, self).__init__()\n",
    "        self.embedding = nn.Embedding(10000, 16)\n",
    "        self.pooling = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc1 = nn.Linear(16, 16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(16, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x).permute(0, 2, 1)\n",
    "        x = self.pooling(x).squeeze()\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = ReviewRegressor()\n",
    "\n",
    "# Définir la fonction de perte et l'optimiseur\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Boucle d'entraînement avec Early Stopping\n",
    "patience = 3\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for reviews, scores in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(reviews)\n",
    "        loss = criterion(outputs.squeeze(), scores)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    val_loss = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for reviews, scores in test_loader:\n",
    "            outputs = model(reviews)\n",
    "            loss = criterion(outputs.squeeze(), scores)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch}, Training Loss: {running_loss/len(train_loader)}, Validation Loss: {val_loss/len(test_loader)}')\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
